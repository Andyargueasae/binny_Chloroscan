Running workflow in current session - don't use this setting except with small datasets and databases.
Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 32
Rules claiming more threads will be scaled down.
Job stats:
job      count    min threads    max threads
-----  -------  -------------  -------------
ALL          1              1              1
binny        1             32             32
total        2              1             32

Select jobs to execute...

[Wed Feb 16 10:57:29 2022]
Job 1: binny: Running Python Binny.

Activating conda environment: /scratch/users/ohickl/binning/tools/binny_devel/conda/9b80527ff49559b8d124b8e535ed36f8
Activating conda environment: /scratch/users/ohickl/binning/tools/binny_devel/conda/9b80527ff49559b8d124b8e535ed36f8
[Wed Feb 16 10:58:46 2022]
Finished job 1.
1 of 2 steps (50%) done
Select jobs to execute...

[Wed Feb 16 10:58:46 2022]
localrule ALL:
    input: bins
    jobid: 0
    resources: tmpdir=/tmp

[Wed Feb 16 10:58:46 2022]
Finished job 0.
2 of 2 steps (100%) done
Complete log: /mnt/lscratch/users/ohickl/binning/tools/binny_devel/.snakemake/log/2022-02-16T105725.920279.snakemake.log
False CPython
Building DAG of jobs...
Creating report...
Downloading resources and rendering HTML.
Loading script code for rule binny
Report created: report.html.
False CPython
