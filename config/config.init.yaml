steps: "preprocessing assembly analysis binning taxonomy summary"
email: ""
sessionName: ""
sessionKind: ""
settingsLocked: "false"
preprocessing_filtering: true
mem:
  normal_mem_per_core_gb: 8
  big_mem_total_gb: 180
  big_mem_cores: 5
  big_mem_per_core_gb: 36
tmp_dir: tmp
raws:
  Metagenomics: "test/Reads/test.mg.1.fastq test/Reads/test.mg.2.fastq"
  Metatranscriptomics: ""
  LongReads: ""
  LongReadTech: ""
  Contigs: ""
  Alignment_metagenomics: ""
  Alignment_metatranscriptomics: ""
  Gff: ""
sample: test
outputdir: "IMP3.initialised"
summarydir: ""
summary_steps: "stats"  # vis
mongo_user: "myUserAdmin"
mongo_port: 16626
mongo_password: "testMongo"
compress_level: "mid"
db_path: "databases"
trimmomatic:
  adapter:
    mg: "TruSeq3-PE"
    mt: "TruSeq3-PE"
  leading: 20
  minlen: 40
  palindrome_clip_threshold: 30
  simple_clip_threshold: 10
  trailing: 20
  seed_mismatch: 2
  window_size: 1
  window_quality: 3
  strictness: 0.5
  target_length: 40
nextseq: false
filtering:
  filter: PhiX # phiX174  Not downloaded?
sortmerna:
  files:
    - rfam-5.8s-database-id98
    - silva-arc-16s-id95
    - silva-bac-16s-id90
    - silva-euk-18s-id95
    - rfam-5s-database-id98
    - silva-arc-23s-id98
    - silva-bac-23s-id98
    - silva-euk-28s-id98
assembly:
  hybrid: true
  assembler: megahit
  merge: "cap3" # how to do merge(assembly A, assembly B from reads not mapping to A); none or "" = use only assembly A
  mink: 25
  maxk: 99
  step: 4
  cap3:
    identity: 98
    overlap: 100
hmm_DBs: "KEGG essential Pfam_A Resfams Cas dbCAN metacyc SwissProt TIGRPFAM"
hmm_settings:
  KEGG:
    cutoff: ""
    trim: "--trimall"
  essential:
    cutoff: "--cut_tc"
    trim: ""
  metacyc:
    cutoff: ""
    trim: "--trimall"
  Cas:
    cutoff: ""
    trim: ""
  Pfam_A:
    cutoff: "--cut_tc"
    trim: ""
  SwissProt:
    cutoff: ""
    trim: "--trimall"
  TIGRPFAM:
    cutoff: ""
    trim: ""
  dbCAN:
    cutoff: ""
    trim: ""
  Resfams:
    cutoff: ""
    trim: ""
COGS: "COG0012 COG0018 COG0215 COG0525 COG0541 COG0016 COG0172 COG0495 COG0533 COG0552"
featureCountsStranding:
  mt: 2
  mg: 0
proteomics:
  filter_N_peptides: 2
  host_proteome: ""
  insert_variants: false
binning:
  binners: "CONCOCT MaxBin MetaBAT binny"
  CONCOCT:
    cutoff: 1000
  MaxBin:
    cutoff: 1000
  MetaBAT:
    cutoff: 1500
  binny:
    kmers: '2,3,4'
    NX_value: 95
    min_cont_length_cutoff: 500
    max_cont_length_cutoff: 1000
    min_cont_length_cutoff_marker: 100
    max_cont_length_cutoff_marker: 300
    max_n_contigs: 3.5e5
    distance_metric: 'manhattan'
    embedding:
      max_iterations: 50
    clustering:
      hdbscan_epsilon_range: '0.500,0.000'
      hdbscan_min_samples_range: '1,2,4,6,8'
      include_depth_initial: 'False'
      include_depth_main: 'True'
    bin_quality:
      min_completeness: 62.5
      start_completeness: 92.5
      purity: 92.5
  MetaWrap:
    min_completeness: 70
    max_contamination: 10
annotation: "mantis" # hmmer (default) / mantis
krakendb: minikraken2
eukdetect:
  run_eukdetect: false
  eukdetect_dir: ../EukDetect
  database_dir: eukdetect_database_v1
  min_readlen: 60 #eukdetect does not recommend pre-trimming, but I don't see why we should keep stuff we don't want
locked_normalMem: 0
locked_bigMem: 0
locked_bigCores: 0
locked_bigTotal: 0
